- #研究想法
- 利用 [[RWKV]] 建模action决策模型，选择哪些任务和方法做benchmark
  利用 预训练[[VLM]] 做信息提取器，利用 VQ-VAE将信息和动作映射到同一空间
- 针对精细任务，增加更多的传感器，对于每一个任务，采用端到端训练一个action model
  如何将不同的ACTION MODEL统一起来
- 如何使用[[Isaac Sim]]提高训练的效率和成功率
- 核心：利用多模态模型做高效的 [[Off Policy Learning]]
- 扩散生成也是一种自回归生成？不过它不是利用上下文的自回归，而是从模糊到清晰的自回归
- 预训练和端到端区别：预训练是首先利用无监督学习训练一个有损tokenizer，再利用该tokenizer训练下游模型
  端到端，所有参数一起进行学习。
- 什么东西能够用transformer做：token分类任务。
- 如何完成任务？训练类似[[思维链]]的东西，让模型学会选择正确的工具API.
- 为什么说大模型只能用于决策而不能完成具体的任务？具体例子就是人，人的决策系统和执行系统并不是一体的，它们是相互关联但又相对独立的两个系统。对于日常的习惯，我们通常可以不经过有意识的决策系统，而是通过潜意识的、自动化的过程来完成。
- 可以将问题转化为决策系统和动作系统。VLA模型通过综合信息决定该采取什么样的动作。问题是VLA模型决策的粒度是什么级别。
- 直接训练机器人能够完成各种任务，端到端的解决方案，我怎么觉得完全不可能呢，动作空间并不是个选择就能完成的，需要不断反馈调节。我更偏向于通过OFF POLICY强化学习训练能够完成各种任务的子模型再由大模型进行决策。
- 点云部分，能否使用gaussian splatting减少存储空间？能否实现动态建图？
	- gaussian存储语义
- 决策部分，如何将rag和cot结合进行合理规划同时能保证规划的可执行性
-
-