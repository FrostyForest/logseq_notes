- #isaaclab #robotics #reinforcement_learning
- 任务目的：
	- 训练出能够利用视觉信息自动追寻物体的模型
	- 学会使用传感器
	- 学会使用强化学习训练框架
	- 学会配置环境
	-
- 首先是在环境中设置方块：
	- ```
	      cube=RigidObjectCfg(
	          prim_path="/World/envs/env_.*/Cube",
	          spawn=sim_utils.CuboidCfg(
	                  size=(0.1, 0.1, 0.1),
	                  visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(1.0, 0.0, 0.0), metallic=0.2),
	                  rigid_props=sim_utils.RigidBodyPropertiesCfg(
	                      solver_position_iteration_count=4, solver_velocity_iteration_count=0
	                  ),
	                  mass_props=sim_utils.MassPropertiesCfg(mass=1.0),
	                  collision_props=sim_utils.CollisionPropertiesCfg(),
	          ),
	          init_state=RigidObjectCfg.InitialStateCfg(
	              pos=(0.5, 0.5, 0.25),
	              rot=(1.0, 0.0, 0.0, 0.0),
	          ),
	      )
	  ```
- 接下来是在环境中设置传感器:
	- 设置相机的姿态比较麻烦，因为相机处于嵌套的局部坐标系中，需要进行转换
	- 使用camera inspector获取camera的local position和orientation
- 接下来是计算夹爪和cube的相对距离
	- 如何获取cube位置
		- cube属于RigidObject，`pos=self.cube.data.body_pos_w[env_ids]`
	- 如何获取夹爪的位置
		- `self.hand_link_idx = self._robot.find_bodies("panda_link7")[0][0]`
		- `hand_pos = self._robot.data.body_pos_w[env_ids, self.hand_link_idx]`
	- 首先计算初始的距离
		- 在初始化和reset的时候都要计算，为此需要两个pos：self.hand_pos和self.cube_pos.
	- 然后计算最新的距离
		- 在计算reward的时候进行计算
	- 然后在计算相对距离作为reward